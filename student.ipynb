{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## t/udom/2017/11787\n",
    "## bsc te\n",
    "\n",
    "# DATA IMBALANCE   \n",
    "#### refers to a problem with classification problems where the classes are not represented equally.\n",
    "#### The following are the methods of data imbalance\n",
    "### we covered 4 different methods for dealing with imbalanced datasets:\n",
    "\n",
    "### 1.Change the performance metric\n",
    "### 2.Oversampling minority class\n",
    "### 3. Undersampling majority class\n",
    "### 4. Change the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continue_drop</th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>caste</th>\n",
       "      <th>mathematics_marks</th>\n",
       "      <th>english_marks</th>\n",
       "      <th>science_marks</th>\n",
       "      <th>science_teacher</th>\n",
       "      <th>languages_teacher</th>\n",
       "      <th>guardian</th>\n",
       "      <th>internet</th>\n",
       "      <th>school_id</th>\n",
       "      <th>total_students</th>\n",
       "      <th>total_toilets</th>\n",
       "      <th>establishment_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continue</td>\n",
       "      <td>s01746</td>\n",
       "      <td>M</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.666</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "      <td>305</td>\n",
       "      <td>354</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continue</td>\n",
       "      <td>s16986</td>\n",
       "      <td>M</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.172</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>mother</td>\n",
       "      <td>False</td>\n",
       "      <td>331</td>\n",
       "      <td>516</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continue</td>\n",
       "      <td>s00147</td>\n",
       "      <td>F</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.212</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>mother</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>209</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continue</td>\n",
       "      <td>s08104</td>\n",
       "      <td>F</td>\n",
       "      <td>ST</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.434</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>father</td>\n",
       "      <td>True</td>\n",
       "      <td>364</td>\n",
       "      <td>147</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continue</td>\n",
       "      <td>s11132</td>\n",
       "      <td>F</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>mother</td>\n",
       "      <td>True</td>\n",
       "      <td>394</td>\n",
       "      <td>122</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1889.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  continue_drop student_id gender caste  mathematics_marks  english_marks  \\\n",
       "0      continue     s01746      M    BC              0.666          0.468   \n",
       "1      continue     s16986      M    BC              0.172          0.420   \n",
       "2      continue     s00147      F    BC              0.212          0.601   \n",
       "3      continue     s08104      F    ST              0.434          0.611   \n",
       "4      continue     s11132      F    SC              0.283          0.478   \n",
       "\n",
       "   science_marks  science_teacher  languages_teacher guardian  internet  \\\n",
       "0          0.666                7                  6    other      True   \n",
       "1          0.172                8                 10   mother     False   \n",
       "2          0.212                1                  4   mother     False   \n",
       "3          0.434                2                  5   father      True   \n",
       "4          0.283                1                 10   mother      True   \n",
       "\n",
       "   school_id  total_students  total_toilets  establishment_year  \n",
       "0        305             354           86.0              1986.0  \n",
       "1        331             516           15.0              1996.0  \n",
       "2        311             209           14.0              1976.0  \n",
       "3        364             147           28.0              1911.0  \n",
       "4        394             122           15.0              1889.0  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\n",
    "data=pd.read_csv('traindata.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "continue_drop           0\n",
       "student_id              0\n",
       "gender                  0\n",
       "caste                   0\n",
       "mathematics_marks       0\n",
       "english_marks           0\n",
       "science_marks           0\n",
       "science_teacher         0\n",
       "languages_teacher       0\n",
       "guardian                0\n",
       "internet                0\n",
       "school_id               0\n",
       "total_students          0\n",
       "total_toilets         312\n",
       "establishment_year    312\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chek nuul values on the colums\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_nums = {\"continue_drop\":{\"continue\":1,\"drop\":0},\n",
    "                \"gender\":{\"F\":0,\"M\":1},\n",
    "                \"caste\":{\"BC\":0,\"SC\":1,\"OC\":2,\"ST\":3},\n",
    "                \"guardian\":{\"mother\":0,\"father\":1,\"other\":2,\"mixed\":3}\n",
    "               }\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "data.internet = data.internet.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('student_id', axis=1, inplace=True)\n",
    "data.drop('total_toilets', axis=1, inplace=True)\n",
    "data.drop('school_id', axis=1, inplace=True)\n",
    "data.drop('establishment_year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    16384\n",
      "0      806\n",
      "Name: continue_drop, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.continue_drop.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring how data hava is imbalancc between continue and drop attribute\n",
    "####                     in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.91943359375"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(data.loc[data.continue_drop==0])) / (len(data.loc[data.continue_drop == 1])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see we have a very imbalanced class - just 4.91% of our dataset belong to the target continue!\n",
    "#### this is a problem because many machine learning models are designed to maximize overall accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=y=data.continue_drop\n",
    "X=data\n",
    "X.drop('continue_drop', axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [1]\n",
      "Test score:  0.9469520707305723\n"
     ]
    }
   ],
   "source": [
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels: ', (np.unique(dummy_pred)))\n",
    "# checking accuracy\n",
    "print('Test score: ', accuracy_score(y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted our accuracy score for classifying all students as to continue is 94.6%!\n",
    "As the Dummy Classifier predicts only Class 0, it is clearly not a good option for our objective of correctly classifying fraudulent transactions.\n",
    "\n",
    "Let's see how logistic regression performs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469520707305723"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling the data as is\n",
    "# Train model\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    " \n",
    "# Predict on training set\n",
    "lr_pred = lr.predict(X_test)\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression are the same with Dummy Classifier! We can see that it predicted acuracy are both th same\n",
    "we have to find better methode of removing imbalance\n",
    "\n",
    "Let's see if we can apply some techniques for dealing with class imbalance to improve these results.\n",
    "\n",
    "### 1. Change the performance metric\n",
    "Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading. Metrics that can provide better insight include:\n",
    "\n",
    "* Confusion Matrix: a talbe showing correct predictions and types of incorrect predictions.\n",
    "* Precision: the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier's exactness. Low precision indicates a high number of false positives.\n",
    "* Recall: the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives.\n",
    "* F1: Score: the weighted average of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4298\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values\n",
    "predictions = pd.DataFrame(lr_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972753346080306"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1\n",
       "0  0   228\n",
       "1  0  4070"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we see tha the best metric to use whic at least can reduce imbalance recall_score, lets another it could be better than this\n",
    "### 2. Change the algorithm\n",
    "While in every machine learning problem, its a good rule of thumb to try a variety of algorithms,\n",
    "it can be especially beneficial with imbalanced datasets. Decision trees frequently perform well on imbalanced data. \n",
    "They work by learning a hierachy of if/else questions. This can force both classes to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# train model\n",
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  228     0\n",
       "1    0  4070"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "recall_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see tha it is at least to use randomforestclassifier than logisticregression due many metrics are \n",
    "supported to reduce imbalance\n",
    "ok lets the third methode\n",
    "## Resampling Techniques\n",
    "### 3. Oversampling Minority Class\n",
    "Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you don't have a ton of data to work with. A con to consider when undersampling is that it can cause overfitting and poor generalization to your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features and target\n",
    "data=pd.read_csv('traindata.csv')\n",
    "cleanup_nums = {\"continue_drop\":{\"continue\":1,\"drop\":0},\n",
    "                \"gender\":{\"F\":0,\"M\":1},\n",
    "                \"caste\":{\"BC\":0,\"SC\":1,\"OC\":2,\"ST\":3},\n",
    "                \"guardian\":{\"mother\":0,\"father\":1,\"other\":2,\"mixed\":3}\n",
    "               }\n",
    "data.replace(cleanup_nums, inplace=True)\n",
    "data.internet = data.internet.astype(int)\n",
    "y=data.continue_drop\n",
    "data.drop('student_id', axis=1, inplace=True)\n",
    "data.drop('total_toilets', axis=1, inplace=True)\n",
    "data.drop('school_id', axis=1, inplace=True)\n",
    "data.drop('establishment_year', axis=1, inplace=True)\n",
    "x=data\n",
    "X = data.drop('continue_drop', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>caste</th>\n",
       "      <th>mathematics_marks</th>\n",
       "      <th>english_marks</th>\n",
       "      <th>science_marks</th>\n",
       "      <th>science_teacher</th>\n",
       "      <th>languages_teacher</th>\n",
       "      <th>guardian</th>\n",
       "      <th>internet</th>\n",
       "      <th>total_students</th>\n",
       "      <th>continue_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.730</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13326</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.337</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.422</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.633</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  caste  mathematics_marks  english_marks  science_marks  \\\n",
       "664         1      0              0.730          0.502          0.730   \n",
       "13326       1      1              0.337          0.283          0.337   \n",
       "11579       0      0              0.416          0.533          0.416   \n",
       "5105        0      1              0.422          0.436          0.422   \n",
       "5514        1      0              0.633          0.885          0.633   \n",
       "\n",
       "       science_teacher  languages_teacher  guardian  internet  total_students  \\\n",
       "664                  6                  3         0         0             469   \n",
       "13326                2                  6         2         1              96   \n",
       "11579                0                  4         0         1             193   \n",
       "5105                 1                  6         0         0             470   \n",
       "5514                 6                  2         0         1             155   \n",
       "\n",
       "       continue_drop  \n",
       "664                1  \n",
       "13326              1  \n",
       "11579              1  \n",
       "5105               1  \n",
       "5514               1  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    806\n",
       "0    806\n",
       "Name: continue_drop, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "not_drop = data[data.continue_drop==1]\n",
    "drop = data[data.continue_drop==0]\n",
    "\n",
    "\n",
    "# upsample minority\n",
    "continue_upsampled = resample(not_drop,replace=True,n_samples=len(drop),random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([drop, continue_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.continue_drop.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = upsampled.continue_drop\n",
    "X_train = upsampled.drop('continue_drop', axis=1)\n",
    "\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6463471382038157"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753473248595921"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1447</td>\n",
       "      <td>2623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0   155    73\n",
       "1  1447  2623"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444717444717445"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy score decreased after upsampling, but the model is now predicting both attributes more equally, \n",
    "making it an improvement over our plain logistic regression above.\n",
    "### 4. Undersampling Majority Class\n",
    "Undersampling can be defined as removing some observations of the majority class. \n",
    "Undersampling can be a good choice when you have a ton of data -think millions of rows. \n",
    "But a drawback to undersampling is that we are removing information that may be valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16384\n",
       "0    16384\n",
       "Name: continue_drop, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsample majority\n",
    "drop_downsampled = resample(drop,\n",
    "                                replace = True, # sample without replacement\n",
    "                                n_samples = len(not_drop), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([drop_downsampled, not_drop])\n",
    "\n",
    "# checking counts\n",
    "downsampled.continue_drop.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the undersampled dataset\n",
    "\n",
    "y_train = downsampled.continue_drop\n",
    "X_train = downsampled.drop('continue_drop', axis=1)\n",
    "\n",
    "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "undersampled_pred = undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6512331316891578"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7807517917215152"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1401</td>\n",
       "      <td>2669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0   130    98\n",
       "1  1401  2669"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, undersampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557739557739558"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We covered 4 different methods for dealing with imbalanced datasets:\n",
    "\n",
    "* Change the performance metric\n",
    "* Oversampling minority class\n",
    "* Undersampling majority class\n",
    "* Change the algorithm\n",
    "\n",
    "the best best methode according to our challenge is usin different allgorithim as we saw some algorithim support many metrics \n",
    "with gooth and avoidance of imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
